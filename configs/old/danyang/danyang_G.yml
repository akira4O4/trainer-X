project_config:
  task: classification
  work_dir: project/danyang_G
  topk: 2
  # print_freq: 10

train_config:
  seed: 114514
  epoch: 0
  max_epoch: 50
  print_freq: 10
  workflow: [ [ train, 1 ], [ val, 1 ] ]
  #  workflow: [[val, 1]]
  deterministic: true
  scheduler_step_batch: true

model_config:
  model_name: shufflenet_v2_x1_0
  num_classes: 2
  pretrained: False
  model_path: D:\code\DLFv2\project\danyang_G\weights\20240110_215806_Epoch10_Acc99.984_lr0.0_BestModel.pth
  gpu: 0 # -1==cpu
  strict: True
  map_location: cpu

classification_data_config:
  train:
    dataset_params:
      root: D:\data\G_train\train
      wh: [ 480,480 ]
      letterbox: true
    dataloader_params:
      batch_size: 64
      shuffle: False
      num_workers: 2
      pin_memory: True
      batch_sampler: BalancedBatchSampler #default:None

  val:
    dataset_params:
      root: D:\data\G_train\train
      wh: [ 480,480 ]
      letterbox: true
    dataloader_params:
      batch_size: 128
      shuffle: false
      num_workers: 1
      pin_memory: True

optimizer_config:
  name: AdamW
  params:
    lr: 0.0002

lr_config:
  #  name: LambdaLR
  #  params:
  #    lr_lambda: "lambda epoch: 1 / (epoch / 4 + 1)" #hook call
  name: CosineAnnealingWarmRestarts
  params:
    T_0: 10
    T_mult: 2

loss_config:
  loss_weights: null

  classification:
    CrossEntropyLoss: { }

ddp_config:
  flag: false
  batch_size: 128
  num_workers: 8
  backend: nccl
  init_method: env://
  rank: 0
  local_rank: 0
  world_size: 1
  # cuda_visible_device: [ 0,1 ]
  sync_bn: false

test_config:
  test_dir: D:\data\0danyang\20240123\good-g
  weight: D:\code\DLFv2\project\danyang_G\weights\20240121_175518_Epoch49_Acc99.7822_lr5.4e-05_BestModel.pth
  # batch_size: 1
  good_idx: 0
  sum_method: true
  need_segment: false
#  cls_threshold: [ 0.5 , 0.7]
  cls_threshold: [ 0.9 , 0.1]
#  seg_threshold: [ 0, 36, 50, 36 ]

