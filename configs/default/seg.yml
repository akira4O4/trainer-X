project_config:
  task: segmentation
  work_dir: project/segmentation
  topk: 2
  print_freq: 5

train_config:
  seed: 0
  epoch: 0
  max_epoch: 1000
  print_freq: 10
  # workflow: [ [ train,1 ] ]
  # workflow: [ [ val,1 ] ]
  workflow: [[train, 1], [val, 1]]
  deterministic: true

model_config:
  model_name: segmentation_shufflenetplus_v2_x1_0
  # num_classes: 2
  mask_classes: 2
  pretrained: False
  model_path: /home/seeking/llf/code/deep_learning_framework/project/exp3/weights/checkpoint.pth
  gpu: 1 # -1==cpu
  strict: True
  map_location: cpu
segmentation_data_config:
  train:
    dataset_params:
      root: "/home/seeking/llf/dataset/gz_sapa_jiayaosai_duanmian/segmentation/train"
      wh: [288, 288]
      letterbox: true
    dataloader_params:
      batch_size: 32
      shuffle: True
      num_workers: 8
      pin_memory: True

  val:
    dataset_params:
      root: "/home/seeking/llf/dataset/gz_sapa_jiayaosai_duanmian/segmentation/train"
      wh: [288, 288]
      letterbox: true
    dataloader_params:
      batch_size: 32
      shuffle: false
      num_workers: 4
      pin_memory: True

optimizer_config:
  name: AdamW
  params:
    lr: 0.001

lr_config:
  name: LambdaLR
  params:
    lr_lambda: "lambda epoch: 1 / (epoch / 4 + 1)" #hook call

loss_config:
  loss_weights: [1, 0.5]
  segmentation:
    PeriodLoss:
      top_k: 0.5
      weight: [1, 1]

    DiceLoss:
      model: MULTICLASS_MODE
      log_loss: false
      from_logits: true
      smooth: 1
      ignore_index: null
      eps: 1.e-7

ddp_config:
  flag: true
  batch_size: 8
  num_workers: 8
  backend: nccl
  init_method: env://
  rank: 0
  local_rank: 0
  world_size: 1
  # cuda_visible_device: [ 0,1 ]
  sync_bn: false
  # sync_performance: False
