project_config:
  task: classification
  work_dir: project/classification
  mlflow_uri: localhost
  mlflow_port: 5000
  mlflow_experiment_name: classification

train_config:
  topk: 2
  seed: 114514
  deterministic: true
  epoch: 0
  max_epoch: 100
  print_freq: 10
  workflow: [ [ train, 1 ], [ val, 1 ] ]
#  scheduler_step_batch: false
  use_torch_2x_compile: true 


model_config:
  model_name: shufflenet_v2_x1_0
  num_classes: 3
  pretrained: False
  model_path: ""
  gpu: 1 # -1==cpu
  strict: True
  map_location: cpu

classification_data_config:
  #---------------------------------------
  dataset:
    train:
      root: /home/main/llf/data/C2_train/train
      wh: [ 480,480 ]
      letterbox: true
    val:
      root: /home/main/llf/data/C2_train/train
      wh: [ 480,480]
      letterbox: true
  #---------------------------------------
  dataloader:
    train:
      batch_size: 128
      shuffle: False
      num_workers: 4
      pin_memory: True
      batch_sampler: BalancedBatchSampler #default:None
    val:
      batch_size: 512
      shuffle: false
      num_workers: 4
      pin_memory: True
  #---------------------------------------

optimizer_config:
  name: AdamW
  params: null
  lr: 0.001

lr_config:
  scheduler_step_in_batch: false
  #plan A
  name: LambdaLR
  optimizer: null
  lr_lambda: "lambda epoch: 1 / (epoch / 4 + 1)" #hook call
  #---------------------------------------
  #plan B
  # name: CosineAnnealingWarmRestarts
  # optimizer: null
  # T_0: 10
  # T_mult: 2

loss_config:
  loss_weights: [ 1 ]
  classification:
    CrossEntropyLoss: { }

test_config:
  test_dir: D:\llf\dataset\danyang\test\256\train\0good
  weight: D:\llf\code\pytorch-lab\project\classification\runs\20240321_160040\weights\20240321_164656_Epoch67_Epoch67_Top1#98.433.pth
  experiment_time: '20240321_160040'
  good_idx: 0
  sum_method: true
  need_segment: true
  cls_threshold: [ 0.2 , 0.85 ]
  seg_threshold: [ 0 ]

