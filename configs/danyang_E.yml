project_config:
  task: classification 
  work_dir: project/danyang_E
  topk: 2
  print_freq: 10

train_config:
  seed: 0
  epoch: 0
  max_epoch: 50
  print_freq: 10
  workflow: [[train, 1], [val, 1]]
  # workflow: [[train, 1]]
  deterministic: true
  scheduler_step_batch: false

model_config:
  model_name: shufflenet_v2_x1_0
  num_classes: 5
  pretrained: False
  model_path: project/danyang_E/weights/checkpoint.pth
  gpu: 0 # -1==cpu
  strict: True
  map_location: cpu

classification_data_config:
  train:
    dataset_params:
      root: /media/seeking/Data1/llf/danyang/E_train
      wh: [928,928]
      letterbox: true
    dataloader_params:
      batch_size: 32
      shuffle: False
      num_workers: 8
      pin_memory: True
      batch_sampler: BalancedBatchSampler #default:None

  val:
    dataset_params:
      root: /media/seeking/Data1/llf/danyang/E_train
      wh: [928,928]
      letterbox: true
    dataloader_params:
      batch_size: 32
      shuffle: false
      num_workers: 8
      pin_memory: True

optimizer_config:
  name: AdamW
  params:
    lr: 0.0003

lr_config:
  name: LambdaLR
  params:
    lr_lambda: "lambda epoch: 1 / (epoch / 4 + 1)" #hook call
  # name: CosineAnnealingWarmRestarts
  # params:
  #   T_0: 10
  #   T_mult: 2

loss_config:
  loss_weights: null

  classification:
    CrossEntropyLoss: {}

ddp_config:
  flag: false
  batch_size: 128
  num_workers: 8
  backend: nccl
  init_method: env://
  rank: 0
  local_rank: 0
  world_size: 1
  # cuda_visible_device: [ 0,1 ]
  sync_bn: false

test_config:
  test_dir: /media/seeking/Data1/llf/danyang/train/0_good
  # test_dir: /media/seeking/Data1/llf/danyang/train/1_shouzhiwen
  # test_dir: /media/seeking/Data1/llf/danyang/train/2_huahen
  weight: project/danyang/weights/checkpoint.pth
  # batch_size: 1
  good_idx: 2
  sum_method: true
  need_segment: false
  cls_threshold: [ 0.3 , 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 ]
  seg_threshold: [ 0, 36, 50, 36 ]

